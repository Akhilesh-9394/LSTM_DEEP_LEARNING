{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_2.0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRKwxo9R_7eR"
      },
      "source": [
        "# model 1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVbucfiH_6H-"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# keras import\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.datasets import imdb\n",
        "# from keras.models import Sequential\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import concatenate, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from datetime import time\n",
        "\n",
        "\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import LSTM, Dropout, Input, Conv1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import he_normal\n",
        "# fix random seed for reproducibility\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(7)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from scipy.sparse import hstack\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import re\n",
        "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "#from gensim.models import Word2Vec\n",
        "#from gensim.models import KeyedVectors\n",
        "#from gensim import corpora\n",
        "import pickle\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYflZwcveWDS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7616358f-a3ff-4774-e524-11302f1bc894"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOx1qR4_eWYK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "ac302532-5d2f-4849-ea5d-ad1a59c3e04f"
      },
      "source": [
        "d = pd.read_csv('/content/drive/My Drive/AAIC assingments/preprocessed_data.csv')\n",
        "d.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school_state</th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>project_grade_category</th>\n",
              "      <th>teacher_number_of_previously_posted_projects</th>\n",
              "      <th>project_is_approved</th>\n",
              "      <th>clean_categories</th>\n",
              "      <th>clean_subcategories</th>\n",
              "      <th>essay</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ca</td>\n",
              "      <td>mrs</td>\n",
              "      <td>grades_prek_2</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>math_science</td>\n",
              "      <td>appliedsciences health_lifescience</td>\n",
              "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
              "      <td>725.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ut</td>\n",
              "      <td>ms</td>\n",
              "      <td>grades_3_5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>specialneeds</td>\n",
              "      <td>specialneeds</td>\n",
              "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
              "      <td>213.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  school_state  ...   price\n",
              "0           ca  ...  725.05\n",
              "1           ut  ...  213.03\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30SavcmneWsp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(d, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WQLCUL2eXAS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "485484bc-e02e-49e9-d45f-dcf4985b5f1a"
      },
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((76473, 9), (32775, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ3IUOkgeXSa"
      },
      "source": [
        "x_train_essay_text = train_df.essay.values.tolist()\n",
        "x_test_essay_text = test_df.essay.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbFSkrlmeXl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a50fa10-1f7f-4b13-980a-c8056109c0af"
      },
      "source": [
        "# tokenizing \n",
        "# https://stackoverflow.com/questions/52126539/using-pretrained-gensim-word2vec-embedding-in-keras\n",
        "# https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(x_train_essay_text)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "print(len(t.word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_oAAuxdeXvF"
      },
      "source": [
        "#this code is taken from below link and changes were made as per our requirement\n",
        "#https://github.com/xSachinBharadwajx/LSTM-DonorsChoose/blob/\n",
        "def load_embedding(filename):\n",
        "\n",
        "    # load embedding into memory, skip first line\n",
        "    file = open(filename,encoding='utf8')\n",
        "    lines = file.readlines()[1:]\n",
        "    \n",
        "    file.close()\n",
        "    # create a map of words to vectors\n",
        "    embedding = dict()\n",
        "    for line in lines:\n",
        "        \n",
        "        parts = line.split()\n",
        "        # key is string word, value is numpy array for vector\n",
        "        embedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n",
        "    return embedding\n",
        "\n",
        "# create a weight matrix for the Embedding layer from a loaded embedding\n",
        "def get_weight_matrix(embedding, vocab):\n",
        "    # total vocabulary size plus 0 for unknown words\n",
        "    vocab_size = len(vocab) + 1\n",
        "    # define weight matrix dimensions with all 0\n",
        "    weight_matrix = np.zeros((vocab_size, 300))\n",
        "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
        "    for word, i in vocab.items():\n",
        "        weight_matrix[i] = embedding.get(word)\n",
        "    return weight_matrix\n",
        "\n",
        "# load embedding from file\n",
        "raw_embedding = load_embedding('/content/drive/My Drive/AAIC assingments/glove.6B.300d.txt')\n",
        "# raw_embedding = load_embedding('glove.42B.300d.txt')\n",
        "\n",
        "# get vectors in the right order\n",
        "embedding_vectors = get_weight_matrix(raw_embedding, t.word_index)\n",
        "where_are_NaNs = np.isnan(embedding_vectors)\n",
        "embedding_vectors[where_are_NaNs] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYiFJkv9eXcs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e851d2e-3f7b-421d-db02-4c5cdc78b4bb"
      },
      "source": [
        "# enocde it to sequences\n",
        "encoded_docs = t.texts_to_sequences(x_train_essay_text)\n",
        "\n",
        "# padding\n",
        "max_length = len(max(x_train_essay_text, key=len).split(' '))\n",
        "\n",
        "x_train_text = sequence.pad_sequences(encoded_docs, maxlen = max_length, padding='post')\n",
        "x_train_text.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 328)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PweHJ5-4eXJ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0881069-733c-4662-c506-7c8ace01a4cf"
      },
      "source": [
        "# enocde it to sequences\n",
        "encoded_docs = t.texts_to_sequences(x_test_essay_text)\n",
        "x_test_text = sequence.pad_sequences(encoded_docs, maxlen = max_length, padding='post')\n",
        "x_test_text.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 328)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nngr7AhceW2M"
      },
      "source": [
        "train_sch_state = train_df.school_state.values.tolist()\n",
        "test_sch_state = test_df.school_state.values.tolist()\n",
        "# no_words = len(set(train_sch_state))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax2mlbpxeWiO"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_sch_state)\n",
        "train_sch_state = tokenizer.texts_to_sequences(train_sch_state)\n",
        "test_sch_state = tokenizer.texts_to_sequences(test_sch_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Re5V3nneWN7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "726cb886-e30a-4719-838b-2df758d73262"
      },
      "source": [
        "max_length = len(max(train_sch_state, key=len))\n",
        "x_train_sch_state = sequence.pad_sequences(train_sch_state, maxlen = max_length, padding='post')\n",
        "x_train_sch_state.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2wLybfueV23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5f03975-acab-434c-b18a-94865f79ff54"
      },
      "source": [
        "x_test_sch_state = sequence.pad_sequences(test_sch_state, maxlen = max_length, padding='post')\n",
        "x_test_sch_state.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wfoRUCPg7tF"
      },
      "source": [
        "train_df['project_grade_category'] = train_df['project_grade_category'].str.replace('_','')\n",
        "test_df['project_grade_category'] = test_df['project_grade_category'].str.replace('_','')\n",
        "# max_length = 1 #len(max(train_proj_grade))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYf2lJeog7-5"
      },
      "source": [
        "train_proj_grade = train_df.project_grade_category.values.tolist()\n",
        "test_proj_grade = test_df.project_grade_category.values.tolist()\n",
        "max_length = 1 #len(max(train_proj_grade))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McNqAyUhg8O0"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_proj_grade)\n",
        "train_proj_grade = tokenizer.texts_to_sequences(train_proj_grade)\n",
        "test_proj_grade = tokenizer.texts_to_sequences(test_proj_grade)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYrf5VKmg8ZZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc5827ab-ae60-4d73-a7c0-26d357a6f20a"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'grades35': 2, 'grades68': 3, 'grades912': 4, 'gradesprek2': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Du2-3ng8U0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ba96e1e-49ef-4efd-e261-44921107921f"
      },
      "source": [
        "x_train_proj_grade = sequence.pad_sequences(train_proj_grade, maxlen = max_length, padding='post')\n",
        "x_train_proj_grade.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftqA2-bxg8GZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86c9de65-73d3-4244-d482-c7cdb399a16d"
      },
      "source": [
        "# Train data\n",
        "x_test_proj_grade = sequence.pad_sequences(test_proj_grade, maxlen = max_length, padding='post')\n",
        "x_test_proj_grade.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jnZj73Ig8FL"
      },
      "source": [
        "train_clean_cat = train_df.clean_categories.values.tolist()\n",
        "test_clean_cat = test_df.clean_categories.values.tolist()\n",
        "# max_length = len(max(train_clean_cat, key=len).split(' '))\n",
        "max_length = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zqGj2GOg70t"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_clean_cat)\n",
        "train_clean_cat = tokenizer.texts_to_sequences(train_clean_cat)\n",
        "test_clean_cat = tokenizer.texts_to_sequences(test_clean_cat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sqcCFmsg7za",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5f33830-de4a-4458-e4c8-e60239978830"
      },
      "source": [
        "# Train data\n",
        "x_train_clean_cat = sequence.pad_sequences(train_clean_cat, maxlen = max_length, padding='post')\n",
        "x_train_clean_cat.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPXLTWV-g7gq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c820afcc-e5d9-4223-df04-2a04a49dc702"
      },
      "source": [
        "# Test data\n",
        "x_test_clean_cat = sequence.pad_sequences(test_clean_cat, maxlen = max_length, padding='post')\n",
        "x_test_clean_cat.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsSZ2Wi6hevb"
      },
      "source": [
        "train_clean_sub_cat = train_df.clean_subcategories.values.tolist()\n",
        "test_clean_sub_cat = test_df.clean_subcategories.values.tolist()\n",
        "max_length = 1#len(max(train_clean_sub_cat, key=len).split(' '))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUjuYRUGhfAw"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_clean_sub_cat)\n",
        "train_clean_sub_cat = tokenizer.texts_to_sequences(train_clean_sub_cat)\n",
        "test_clean_sub_cat = tokenizer.texts_to_sequences(test_clean_sub_cat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y8zrpM1hfYA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b76d5727-9967-4330-d6a0-770dcbc218ee"
      },
      "source": [
        "# Train data\n",
        "x_train_clean_sub_cat = sequence.pad_sequences(train_clean_sub_cat, maxlen = max_length, padding='post')\n",
        "x_train_clean_sub_cat.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQp5jKYIhfOt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cbac99c1-a2bb-4ccb-96e4-b4d695eb2d51"
      },
      "source": [
        "# Test data\n",
        "x_test_clean_sub_cat = sequence.pad_sequences(test_clean_sub_cat, maxlen = max_length, padding='post')\n",
        "x_test_clean_sub_cat.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwkb65Vnhe3L"
      },
      "source": [
        "train_teacher_prefix = train_df.teacher_prefix.values.tolist()\n",
        "test_teacher_prefix = test_df.teacher_prefix.values.tolist()\n",
        "max_length = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqOdBCMrhepn"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_teacher_prefix)\n",
        "train_teacher_prefix = tokenizer.texts_to_sequences(train_teacher_prefix)\n",
        "test_teacher_prefix = tokenizer.texts_to_sequences(test_teacher_prefix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLY8hrDSheoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "03d89045-d2df-48f7-d3f0-3184d027d409"
      },
      "source": [
        "# Train data\n",
        "x_train_teacher_prefix = sequence.pad_sequences(train_teacher_prefix, maxlen = max_length, padding='post')\n",
        "x_train_teacher_prefix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOXDthgzh8Ii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5eb3fb3-e4d5-47e7-b902-a8a466292f95"
      },
      "source": [
        "# Train data\n",
        "x_test_teacher_prefix = sequence.pad_sequences(test_teacher_prefix, maxlen = max_length, padding='post')\n",
        "x_test_teacher_prefix.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMA8UGX1h8dd"
      },
      "source": [
        "x_train_previously_posted_projects = train_df['teacher_number_of_previously_posted_projects']#train_df.teacher_number_of_previously_posted_projects.values\n",
        "#x_train_previously_posted_projects = x_train_previously_posted_projects.reshape(76473, 1)\n",
        "#x_train_previously_posted_projects.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EERPzR1Dh8w3"
      },
      "source": [
        "x_test_previously_posted_projects = test_df['teacher_number_of_previously_posted_projects']#test_df.teacher_number_of_previously_posted_projects.values\n",
        "#x_test_previously_posted_projects = x_test_previously_posted_projects.reshape(32775, 1)\n",
        "#x_test_previously_posted_projects.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlPOjbq2h8nj"
      },
      "source": [
        "# https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
        "def auroc(y_true, y_pred):\n",
        "    # print(y_true, y_pred)\n",
        "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD1uE9DZh8Sz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2efebd5-b5e5-40ad-cd74-ee887d63c052"
      },
      "source": [
        "#input 1\n",
        "input_1 = Input(shape=(328,))\n",
        "x1 =Embedding(vocab_size, 300, weights=[embedding_vectors], input_length=x_train_text.shape[1], trainable=False)(input_1)\n",
        "x1 = Dropout(0.5)(x1)\n",
        "x1 = LSTM(128,return_sequences=True)(x1)\n",
        "x1 = Flatten()(x1)\n",
        "\n",
        "#input 2\n",
        "input_2 = Input(shape=(1,))\n",
        "x2 = Embedding(input_dim= 52, output_dim= 2)(input_2)\n",
        "x2 = Flatten()(x2)\n",
        "\n",
        "#input 3\n",
        "input_3 = Input(shape=(1,))\n",
        "x3 = Embedding(input_dim = 5, output_dim= 2)(input_3)\n",
        "x3 = Flatten()(x3)\n",
        "\n",
        "#input 4\n",
        "input_4 = Input(shape=(1,))\n",
        "x4 = Embedding(input_dim=52,output_dim= 2)(input_4)\n",
        "x4 = Flatten()(x4)\n",
        "\n",
        "#input 5\n",
        "input_5 = Input(shape=(1,))\n",
        "x5 = Embedding(input_dim= 396, output_dim= 64)(input_5)\n",
        "x5 = Flatten()(x5)\n",
        "\n",
        "#input 6\n",
        "input_6 = Input(shape=(1,))\n",
        "x6 = Embedding(input_dim= 6,output_dim= 4)(input_6)\n",
        "x6 = Flatten()(x6)\n",
        "\n",
        "#input 7\n",
        "input_7 = Input(shape=(1,))\n",
        "x7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input_7)\n",
        "\n",
        "#merging all the inputs \n",
        "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
        "#x = BatchNormalization()(concat)\n",
        "\n",
        "x = Dense(128, activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
        "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(2, activation = 'softmax')(x)\n",
        "\n",
        "# model with all the inputs\n",
        "model = Model([input_1, input_2, input_3, input_4, input_5, input_6, input_7], output)\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0006,decay = 1e-4), metrics=[auroc])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 328)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 328, 300)     14726100    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 328, 300)     0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 328, 128)     219648      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 2)         104         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1, 2)         10          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1, 2)         104         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 64)        25344       input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 4)         24          input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 41984)        0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2)            0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 2)            0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 64)           0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 4)            0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 16)           32          input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 42074)        0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "                                                                 flatten_4[0][0]                  \n",
            "                                                                 flatten_5[0][0]                  \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          5385600     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 64)           256         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           2080        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 2)            66          dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 20,367,624\n",
            "Trainable params: 5,641,396\n",
            "Non-trainable params: 14,726,228\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ObrOa4Fh79E"
      },
      "source": [
        "y_train = train_df.project_is_approved.values.tolist()\n",
        "y_test = test_df.project_is_approved.values.tolist()\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIhAVtw-iYpN"
      },
      "source": [
        "x_train =  [x_train_text, x_train_sch_state, x_train_proj_grade, x_train_clean_cat, x_train_clean_sub_cat, x_train_teacher_prefix, x_train_previously_posted_projects]\n",
        "x_test = [x_test_text, x_test_sch_state, x_test_proj_grade, x_test_clean_cat, x_test_clean_sub_cat, x_test_teacher_prefix, x_test_previously_posted_projects]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho_a9JYqid3Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "outputId": "b9db3586-6dfc-40ab-927c-bdbce44011ce"
      },
      "source": [
        "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model.fit(x_train, y_train, epochs=10,verbose=1,batch_size=128, callbacks =callbacks_list)\n",
        "# model.save('dc_model1.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4019 - auroc: 0.7345WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 45ms/step - loss: 0.4019 - auroc: 0.7345\n",
            "Epoch 2/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3997 - auroc: 0.7367WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 45ms/step - loss: 0.3997 - auroc: 0.7367\n",
            "Epoch 3/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3975 - auroc: 0.7413WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 45ms/step - loss: 0.3975 - auroc: 0.7413\n",
            "Epoch 4/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3958 - auroc: 0.7464WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 28s 46ms/step - loss: 0.3958 - auroc: 0.7465\n",
            "Epoch 5/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3947 - auroc: 0.7504WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 28s 46ms/step - loss: 0.3948 - auroc: 0.7503\n",
            "Epoch 6/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3923 - auroc: 0.7592WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 28s 46ms/step - loss: 0.3924 - auroc: 0.7592\n",
            "Epoch 7/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3915 - auroc: 0.7628WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 28s 46ms/step - loss: 0.3915 - auroc: 0.7627\n",
            "Epoch 8/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3873 - auroc: 0.7729WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 28s 46ms/step - loss: 0.3873 - auroc: 0.7729\n",
            "Epoch 9/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3857 - auroc: 0.7799WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 28s 46ms/step - loss: 0.3857 - auroc: 0.7796\n",
            "Epoch 10/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3825 - auroc: 0.7906WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 28s 46ms/step - loss: 0.3825 - auroc: 0.7908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f422e6adc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HZNxRpUwgPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e46fe29f-394a-4817-89bb-f188a7af299a"
      },
      "source": [
        "### Testing model-1\n",
        "y_train_pred = model.predict(x_train)\n",
        "print(\"Train AUC:\",roc_auc_score(y_train,y_train_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train AUC: 0.8458312473785294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRIHUgddwgpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a586eaa3-5c18-466b-cc78-ab1636af1267"
      },
      "source": [
        "y_test_pred = model.predict(x_test)\n",
        "print(\"Test AUC:\",roc_auc_score(y_test,y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test AUC: 0.7513362235737617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTN7nwaEw93R"
      },
      "source": [
        "# model 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjlm0OVVwgdn"
      },
      "source": [
        "# Save to file in the current working directory\n",
        "def saveModel(filename, model):\n",
        "    try:\n",
        "        import cPickle as pickle\n",
        "\n",
        "    except ImportError:\n",
        "        import pickle\n",
        "\n",
        "    with open(filename, 'wb') as fp:\n",
        "        pickle.dump(model, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3kXcfpfwgAa"
      },
      "source": [
        "# Load from file\n",
        "def getModel(pkl_filename):\n",
        "    with open(pkl_filename, 'rb') as file:\n",
        "        pickle_model = pickle.load(file)\n",
        "    return pickle_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO6qZOkJxZxA"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFktlAVqxaPQ"
      },
      "source": [
        "x_train_essay_text = train_df.essay.values.tolist()\n",
        "x_test_essay_text = test_df.essay.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyGxcwjvxaA-"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df=10, max_features=10000)\n",
        "vectorizer.fit(x_train_essay_text) \n",
        "x_train_tfidf  = vectorizer.transform(x_train_essay_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5o03HELxZgQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "59d775ca-e21d-4eb6-a64c-d578ca8be458"
      },
      "source": [
        "# box plot to decide the threshold\n",
        "plt.boxplot(vectorizer.idf_)\n",
        "plt.ylabel(\"IDF Value\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'IDF Value')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKr1-Mv8xsSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "059cadb1-19a6-4428-e57b-3e1ec71f9aaf"
      },
      "source": [
        "# sortedDiff =np.sort(diff)\n",
        "for i in range (0,101,10):\n",
        "    p = np.percentile(vectorizer.idf_, i)\n",
        "    print(str(i)+\" Percentile: \"+ str(p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Percentile: 1.0077317773707817\n",
            "10 Percentile: 4.961189206264439\n",
            "20 Percentile: 5.876176147118889\n",
            "30 Percentile: 6.59925919512169\n",
            "40 Percentile: 7.108907655714666\n",
            "50 Percentile: 7.5442257269725115\n",
            "60 Percentile: 7.887997266075336\n",
            "70 Percentile: 8.201654824930378\n",
            "80 Percentile: 8.50703647448156\n",
            "90 Percentile: 8.7789701899652\n",
            "100 Percentile: 9.846810819966556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elLcpt47xs3v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea870c06-49d6-4321-d97e-d715dab0aecc"
      },
      "source": [
        "min_threshold = 3 # np.percentile(vectorizer.idf_, 20)\n",
        "max_threshold = np.percentile(vectorizer.idf_, 90)\n",
        "print(min_threshold, max_threshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 8.7789701899652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4G1FRH5xspW"
      },
      "source": [
        "feat = vectorizer.get_feature_names()\n",
        "idf_val = vectorizer.idf_\n",
        "len(feat), len(idf_val)\n",
        "feat_idf_dict = dict(zip(feat, idf_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr6mKZc3xsEg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac3cac2c-3105-4f97-c4b3-ea202621c398"
      },
      "source": [
        "# new_data = {k: v for k, v in feat_idf_dict.iteritems() if min_threshold < v[0] < max_threshold}\n",
        "for k  in list(feat_idf_dict.keys()):\n",
        "    # removing low and high idf features\n",
        "    if (min_threshold >= feat_idf_dict[k]) or (feat_idf_dict[k] >= max_threshold):\n",
        "        feat_idf_dict.pop(k)\n",
        "\n",
        "len(feat_idf_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8831"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWks28YwySzB"
      },
      "source": [
        "import tqdm\n",
        "# removing low and high idf words from dataset\n",
        "def get_filtered_text(text_dataset):\n",
        "\n",
        "    \n",
        "  filtered_text = []\n",
        "\n",
        "  for text in (text_dataset):\n",
        "    resultwords  = [word for word in text.split() if word.lower() in list(feat_idf_dict.keys())]\n",
        "    result = ' '.join(resultwords)\n",
        "    filtered_text.append(result)\n",
        "    \n",
        "  return filtered_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwGg0ioDySla"
      },
      "source": [
        "\n",
        "x_train_essay_text_filtered = get_filtered_text(x_train_essay_text)\n",
        "saveModel(\"x_train_tfidf_filter_3.pkl\", x_train_essay_text_filtered)\n",
        "\n",
        "\n",
        "#x_train_essay_text_filtered = getModel(\"x_train_tfidf_filter_3.pkl\")\n",
        "#x_test_essay_text_filtered = getModel(\"x_test_tfidf_filter_3.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X06MKlc-1Jhs"
      },
      "source": [
        "x_test_essay_text_filtered = get_filtered_text(x_test_essay_text)\n",
        "saveModel(\"x_test_tfidf_filter_3.pkl\", x_test_essay_text_filtered)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKAyEcRpAOrE"
      },
      "source": [
        "x_train_essay_text_filtered = getModel(\"x_train_tfidf_filter_3.pkl\")\n",
        "x_test_essay_text_filtered = getModel(\"x_test_tfidf_filter_3.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMTLd4y9K2xY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ced59d6f-03a5-4941-c872-87ffb00aef36"
      },
      "source": [
        "# tokenizing \n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(x_train_essay_text_filtered)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "print(len(t.word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcztx219K_48"
      },
      "source": [
        "def load_embedding(filename):\n",
        "\n",
        "    # load embedding into memory, skip first line\n",
        "    file = open(filename, 'r')\n",
        "    lines = file.readlines()[1:]\n",
        "    \n",
        "    file.close()\n",
        "    # create a map of words to vectors\n",
        "    embedding = dict()\n",
        "    for line in lines:\n",
        "        \n",
        "        parts = line.split()\n",
        "        # key is string word, value is numpy array for vector\n",
        "        embedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n",
        "    return embedding\n",
        "\n",
        "# create a weight matrix for the Embedding layer from a loaded embedding\n",
        "def get_weight_matrix(embedding, vocab):\n",
        "    # total vocabulary size plus 0 for unknown words\n",
        "    vocab_size = len(vocab) + 1\n",
        "    # define weight matrix dimensions with all 0\n",
        "    weight_matrix = np.zeros((vocab_size, 300))\n",
        "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
        "    for word, i in vocab.items():\n",
        "        weight_matrix[i] = embedding.get(word)\n",
        "    return weight_matrix\n",
        "\n",
        "# load embedding from file\n",
        "raw_embedding = load_embedding('/content/drive/My Drive/AAIC assingments/glove.6B.300d.txt')\n",
        "# raw_embedding = load_embedding('glove.42B.300d.txt')\n",
        "\n",
        "# get vectors in the right order\n",
        "embedding_vectors = get_weight_matrix(raw_embedding, t.word_index)\n",
        "where_are_NaNs = np.isnan(embedding_vectors)\n",
        "embedding_vectors[where_are_NaNs] = 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXBLwIU9K_qh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31803dfc-4f60-4e2d-9d98-5366e42349f3"
      },
      "source": [
        "# Train\n",
        "# enocde it to sequences\n",
        "encoded_docs = t.texts_to_sequences(x_train_essay_text_filtered)\n",
        "max_length = len(max(x_train_essay_text_filtered, key=len).split(' '))\n",
        "x_train_text_M2 = sequence.pad_sequences(encoded_docs, maxlen = max_length, padding='post')\n",
        "x_train_text_M2.shape\n",
        "\n",
        "# Test\n",
        "encoded_docs = t.texts_to_sequences(x_test_essay_text_filtered)\n",
        "x_test_text_M2 = sequence.pad_sequences(encoded_docs, maxlen = max_length, padding='post')\n",
        "x_test_text_M2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32775, 216)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgxQRTXBMfRp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2362c308-de32-4b88-9163-ba0691fb7fab"
      },
      "source": [
        "x_train_text_M2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76473, 216)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0PrUhd9MlEW"
      },
      "source": [
        "# https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
        "def auroc(y_true, y_pred):\n",
        "    # print(y_true, y_pred)\n",
        "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz3OGjo3MklF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "822f78a6-bcd5-432c-df30-4f262cd408ff"
      },
      "source": [
        "#input 1\n",
        "input_1 = Input(shape=(216,))\n",
        "x1 =Embedding(vocab_size, 300, weights=[embedding_vectors], input_length=x_train_text_M2.shape[1], trainable=False)(input_1)\n",
        "x1 = Dropout(0.4)(x1)\n",
        "x1 = LSTM(128,return_sequences=True)(x1)\n",
        "x1 = Flatten()(x1)\n",
        "\n",
        "#input 2\n",
        "input_2 = Input(shape=(1,))\n",
        "x2 = Embedding(input_dim= 52, output_dim= 2)(input_2)\n",
        "x2 = Flatten()(x2)\n",
        "\n",
        "#input 3\n",
        "input_3 = Input(shape=(1,))\n",
        "x3 = Embedding(input_dim = 5, output_dim= 2)(input_3)\n",
        "x3 = Flatten()(x3)\n",
        "\n",
        "#input 4\n",
        "input_4 = Input(shape=(1,))\n",
        "x4 = Embedding(input_dim=52,output_dim= 2)(input_4)\n",
        "x4 = Flatten()(x4)\n",
        "\n",
        "#input 5\n",
        "input_5 = Input(shape=(1,))\n",
        "x5 = Embedding(input_dim= 396, output_dim= 64)(input_5)\n",
        "x5 = Flatten()(x5)\n",
        "\n",
        "#input 6\n",
        "input_6 = Input(shape=(1,))\n",
        "x6 = Embedding(input_dim= 6,output_dim= 4)(input_6)\n",
        "x6 = Flatten()(x6)\n",
        "\n",
        "#input 7\n",
        "input_7 = Input(shape=(1,))\n",
        "x7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input_7)\n",
        "\n",
        "#merging all the inputs \n",
        "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
        "#x = BatchNormalization()(concat)\n",
        "\n",
        "x = Dense(128, activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(2, activation = 'softmax')(x)\n",
        "\n",
        "# model with all the inputs\n",
        "model = Model([input_1, input_2, input_3, input_4, input_5, input_6, input_7], output)\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0006,decay = 1e-4), metrics=[auroc])\n",
        "print(model.summary())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_30 (InputLayer)           [(None, 216)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_25 (Embedding)        (None, 216, 300)     2649600     input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 216, 300)     0           embedding_25[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_31 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_32 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_33 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_34 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_35 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 216, 128)     219648      dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_26 (Embedding)        (None, 1, 2)         104         input_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_27 (Embedding)        (None, 1, 2)         10          input_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_28 (Embedding)        (None, 1, 2)         104         input_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_29 (Embedding)        (None, 1, 64)        25344       input_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_30 (Embedding)        (None, 1, 4)         24          input_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_36 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_24 (Flatten)            (None, 27648)        0           lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_25 (Flatten)            (None, 2)            0           embedding_26[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_26 (Flatten)            (None, 2)            0           embedding_27[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_27 (Flatten)            (None, 2)            0           embedding_28[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_28 (Flatten)            (None, 64)           0           embedding_29[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_29 (Flatten)            (None, 4)            0           embedding_30[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 16)           32          input_36[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 27738)        0           flatten_24[0][0]                 \n",
            "                                                                 flatten_25[0][0]                 \n",
            "                                                                 flatten_26[0][0]                 \n",
            "                                                                 flatten_27[0][0]                 \n",
            "                                                                 flatten_28[0][0]                 \n",
            "                                                                 flatten_29[0][0]                 \n",
            "                                                                 dense_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 128)          3550592     concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 128)          0           dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 64)           8256        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 64)           0           dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64)           256         dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 32)           2080        batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 32)           0           dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 2)            66          dropout_18[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 6,456,116\n",
            "Trainable params: 3,806,388\n",
            "Non-trainable params: 2,649,728\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-1noVHlNm5Z"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = train_df.project_is_approved.values.tolist()\n",
        "y_test = test_df.project_is_approved.values.tolist()\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8vDHYNvNpQE"
      },
      "source": [
        "x_train =  [x_train_text_M2, x_train_sch_state, x_train_proj_grade, x_train_clean_cat, x_train_clean_sub_cat, x_train_teacher_prefix, x_train_previously_posted_projects]\n",
        "x_test = [x_test_text_M2, x_test_sch_state, x_test_proj_grade, x_test_clean_cat, x_test_clean_sub_cat, x_test_teacher_prefix, x_test_previously_posted_projects]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN_y2zsAN1nB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ca41953-076c-4d7c-e56b-394d84881cf2"
      },
      "source": [
        "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
        "filepath = \"weight_model2_v3.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint,tensorboard]\n",
        "model.fit(x_train, y_train, epochs=20,verbose=1,batch_size=128, callbacks =callbacks_list)\n",
        "model.save('dc_model2_v4.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  2/598 [..............................] - ETA: 1:00 - loss: 0.7999 - auroc: 0.5381WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0356s vs `on_train_batch_end` time: 0.1662s). Check your callbacks.\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.5670 - auroc: 0.5609WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.5670 - auroc: 0.5609\n",
            "Epoch 2/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4715 - auroc: 0.6352WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.4715 - auroc: 0.6352\n",
            "Epoch 3/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4455 - auroc: 0.6716WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.4455 - auroc: 0.6716\n",
            "Epoch 4/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4311 - auroc: 0.6887WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.4311 - auroc: 0.6887\n",
            "Epoch 5/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4223 - auroc: 0.6965WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.4224 - auroc: 0.6963\n",
            "Epoch 6/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4149 - auroc: 0.7047WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.4149 - auroc: 0.7046\n",
            "Epoch 7/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4098 - auroc: 0.7133WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.4099 - auroc: 0.7132\n",
            "Epoch 8/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4064 - auroc: 0.7180WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.4063 - auroc: 0.7179\n",
            "Epoch 9/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4034 - auroc: 0.7227WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.4033 - auroc: 0.7231\n",
            "Epoch 10/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4042 - auroc: 0.7246WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.4042 - auroc: 0.7246\n",
            "Epoch 11/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4005 - auroc: 0.7347WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.4005 - auroc: 0.7348\n",
            "Epoch 12/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3960 - auroc: 0.7404WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.3961 - auroc: 0.7402\n",
            "Epoch 13/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3940 - auroc: 0.7488WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.3939 - auroc: 0.7486\n",
            "Epoch 14/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3909 - auroc: 0.7521WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.3909 - auroc: 0.7522\n",
            "Epoch 15/20\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.3882 - auroc: 0.7597WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.3882 - auroc: 0.7597\n",
            "Epoch 16/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3834 - auroc: 0.7706WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 33ms/step - loss: 0.3834 - auroc: 0.7707\n",
            "Epoch 17/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3817 - auroc: 0.7758WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.3817 - auroc: 0.7757\n",
            "Epoch 18/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3790 - auroc: 0.7840WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.3790 - auroc: 0.7839\n",
            "Epoch 19/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3761 - auroc: 0.7900WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.3759 - auroc: 0.7903\n",
            "Epoch 20/20\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.3695 - auroc: 0.8040WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 19s 32ms/step - loss: 0.3695 - auroc: 0.8040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EN54r8uUEyR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "411a2e66-ebd3-4701-ecb8-13ef3a0f74d7"
      },
      "source": [
        "### Testing model-2\n",
        "y_train_pred = model.predict(x_train)\n",
        "print(\"Train AUC:\",roc_auc_score(y_train,y_train_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train AUC: 0.8691214777601453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP4M-27IUIPx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f13e097-d56c-4e3b-85b8-cebf94df2094"
      },
      "source": [
        "y_test_pred = model.predict(x_test)\n",
        "print(\"Test AUC:\",roc_auc_score(y_test,y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test AUC: 0.7164262407988157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJPZ3uGoWe-S"
      },
      "source": [
        "# model 3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5TuouY5WnrR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "42704326-d2b2-4fbf-dbf5-204315e78168"
      },
      "source": [
        "# http://flovv.github.io/Embeddings_with_keras_part2/\n",
        "# school state\n",
        "token = CountVectorizer()\n",
        "# integer encode the documents\n",
        "x_train_sch_state = token.fit_transform(train_df.school_state)\n",
        "x_test_sch_state = token.transform(test_df.school_state)\n",
        "print(x_train_sch_state.shape, x_test_sch_state.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 51) (32775, 51)\n",
            "(76473, 51) (32775, 51)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNC49NjdXFP5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b62cb55-dddf-4f71-d41c-393f400293fe"
      },
      "source": [
        "# proj_grade\n",
        "token = CountVectorizer()\n",
        "# integer encode the documents\n",
        "x_train_proj_grade = token.fit_transform(train_df.project_grade_category)\n",
        "x_test_proj_grade = token.transform(test_df.project_grade_category)\n",
        "print(x_train_proj_grade.shape, x_test_proj_grade.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 4) (32775, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWgmNRwHXFxb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2f2b682-d488-4010-bef8-569d7a28f53d"
      },
      "source": [
        "# clean_cat\n",
        "token = CountVectorizer()\n",
        "# integer encode the documents\n",
        "x_train_clean_cat = token.fit_transform(train_df.clean_categories)\n",
        "x_test_clean_cat = token.transform(test_df.clean_categories)\n",
        "print(x_train_clean_cat.shape, x_test_clean_cat.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 9) (32775, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGH7IOcbXGFM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bfebc4b1-28c3-4a5e-da95-549b9acd8ade"
      },
      "source": [
        "# x_train_clean_sub_cat\n",
        "token = CountVectorizer()\n",
        "# integer encode the documents\n",
        "x_train_clean_sub_cat = token.fit_transform(train_df.clean_subcategories)\n",
        "x_test_clean_sub_cat = token.transform(test_df.clean_subcategories)\n",
        "print(x_train_clean_sub_cat.shape, x_test_clean_sub_cat.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 30) (32775, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekTmyoj-XFi9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06c39284-537c-414b-a03a-c4a32f1110f5"
      },
      "source": [
        "# x_train_teacher_prefix\n",
        "token = CountVectorizer()\n",
        "# integer encode the documents\n",
        "x_train_teacher_prefix = token.fit_transform(train_df.teacher_prefix)\n",
        "x_test_teacher_prefix = token.transform(test_df.teacher_prefix)\n",
        "print(x_train_teacher_prefix.shape, x_test_teacher_prefix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 5) (32775, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ7hfRIxXEi_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96e6cd64-73f2-48b9-907e-15d825f97b89"
      },
      "source": [
        "x_train_previously_posted_projects = train_df.teacher_number_of_previously_posted_projects.values\n",
        "x_train_previously_posted_projects = x_train_previously_posted_projects.reshape(76473, 1)\n",
        "#x_train_previously_posted_projects.shape\n",
        "x_test_previously_posted_projects = test_df.teacher_number_of_previously_posted_projects.values\n",
        "x_test_previously_posted_projects = x_test_previously_posted_projects.reshape(32775, 1)\n",
        "print(x_train_previously_posted_projects.shape, x_test_previously_posted_projects.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(76473, 1) (32775, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oUlZlzbXdwx"
      },
      "source": [
        "### input_1\n",
        "x_train_1 =  x_train_text\n",
        "x_test_1 =  x_test_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPb7NwN-XeDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5009681d-22f1-42a0-a822-3438cca0ef79"
      },
      "source": [
        "### input 2\n",
        "x_train_2 = hstack((x_train_sch_state, x_train_proj_grade, x_train_clean_cat, x_train_clean_sub_cat, x_train_teacher_prefix, x_train_previously_posted_projects)).todense()\n",
        "x_train_2 = np.array(x_train_2).reshape(x_train_2.shape[0],x_train_2.shape[1],1)\n",
        "\n",
        "x_test_2 = hstack((x_test_sch_state, x_test_proj_grade, x_test_clean_cat, x_test_clean_sub_cat, x_test_teacher_prefix, x_test_previously_posted_projects)).todense()\n",
        "x_test_2 = np.array(x_test_2).reshape(x_test_2.shape[0],x_test_2.shape[1],1)\n",
        "\n",
        "x_train_2.shape, x_test_2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((76473, 100, 1), (32775, 100, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpClNEPtXdhE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def auroc(y_true, y_pred):\n",
        "#     print(y_true, y_pred)\n",
        "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM7yk9Imvv5k"
      },
      "source": [
        "from keras.layers import LeakyReLU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3fMM4xKXrU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "outputId": "23be4f59-d6b6-4368-f6e1-ebf4a137474d"
      },
      "source": [
        "# input 1\n",
        "input_1 = Input(shape=(328,))\n",
        "x1 =Embedding(vocab_size, 300, weights=[embedding_vectors], input_length=x_train_text.shape[1], trainable=False)(input_1)\n",
        "x1 = Dropout(0.5)(x1)\n",
        "x1 = LSTM(128,return_sequences=True)(x1)\n",
        "x1 = Flatten()(x1)\n",
        "\n",
        "# input 2\n",
        "input_2 = Input(shape=(100,1))\n",
        "x2 = Conv1D(filters=128,kernel_size=3, strides=1)(input_2)\n",
        "x2 = Conv1D(filters=64,kernel_size=3, strides=1)(x2)\n",
        "x2 = Flatten()(x2)\n",
        "\n",
        "\n",
        "# merging both the inputs\n",
        "concat = concatenate([x1,x2])\n",
        "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
        "x = Dropout(0.6)(x)\n",
        "output = Dense(2, activation = 'softmax')(x)\n",
        " \n",
        "# create model with two inputs\n",
        "model = Model([input_1,input_2], output)\n",
        "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0006,decay = 1e-4), metrics=[auroc])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_22 (InputLayer)           [(None, 328)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_13 (Embedding)        (None, 328, 300)     14726100    input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_23 (InputLayer)           [(None, 100, 1)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 328, 300)     0           embedding_13[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 98, 128)      512         input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   (None, 328, 128)     219648      dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 96, 64)       24640       conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_20 (Flatten)            (None, 41984)        0           lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_21 (Flatten)            (None, 6144)         0           conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 48128)        0           flatten_20[0][0]                 \n",
            "                                                                 flatten_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 128)          6160512     concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 128)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 64)           8256        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 64)           0           dense_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64)           256         dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 32)           2080        batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 32)           0           dense_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 2)            66          dropout_19[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 21,142,070\n",
            "Trainable params: 6,415,842\n",
            "Non-trainable params: 14,726,228\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNv45jdUXrFL"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = train_df.project_is_approved.values.tolist()\n",
        "y_test = test_df.project_is_approved.values.tolist()\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUQaValtX1I9"
      },
      "source": [
        "x_train = [x_train_1, x_train_2]\n",
        "x_test  = [x_test_1, x_test_2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHrJco8RX5Aw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "9a16a812-2844-48ab-9869-f915442f0b0a"
      },
      "source": [
        "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
        "filepath = \"weight_model2_v3.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint,tensorboard]\n",
        "model.fit(x_train, y_train, epochs=10,verbose=1,batch_size=128, callbacks =callbacks_list)\n",
        "# model.save('dc_model3.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  2/598 [..............................] - ETA: 1:06 - loss: 1.5826 - auroc: 0.4345WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0629s vs `on_train_batch_end` time: 0.1454s). Check your callbacks.\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.6587 - auroc: 0.5122WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 45ms/step - loss: 0.6586 - auroc: 0.5123\n",
            "Epoch 2/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.5033 - auroc: 0.5422WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 45ms/step - loss: 0.5033 - auroc: 0.5422\n",
            "Epoch 3/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4704 - auroc: 0.5893WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 45ms/step - loss: 0.4704 - auroc: 0.5893\n",
            "Epoch 4/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4540 - auroc: 0.6178WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 45ms/step - loss: 0.4540 - auroc: 0.6178\n",
            "Epoch 5/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4343 - auroc: 0.6736WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 45ms/step - loss: 0.4343 - auroc: 0.6736\n",
            "Epoch 6/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4241 - auroc: 0.6943WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 46ms/step - loss: 0.4241 - auroc: 0.6943\n",
            "Epoch 7/10\n",
            "597/598 [============================>.] - ETA: 0s - loss: 0.4173 - auroc: 0.7042WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 46ms/step - loss: 0.4173 - auroc: 0.7043\n",
            "Epoch 8/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4131 - auroc: 0.7138WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 27s 46ms/step - loss: 0.4131 - auroc: 0.7138\n",
            "Epoch 9/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4081 - auroc: 0.7231WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 28s 46ms/step - loss: 0.4081 - auroc: 0.7231\n",
            "Epoch 10/10\n",
            "598/598 [==============================] - ETA: 0s - loss: 0.4062 - auroc: 0.7261WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
            "598/598 [==============================] - 28s 46ms/step - loss: 0.4062 - auroc: 0.7261\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f422f3f9cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG9Bqr8KrexJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0b758a36-6b25-4cf4-cbc8-534632bafda0"
      },
      "source": [
        "### Testing model-3\n",
        "y_train_pred = model.predict(x_train)\n",
        "print(\"Train AUC:\",roc_auc_score(y_train,y_train_pred))\n",
        "\n",
        "y_test_pred = model.predict(x_test)\n",
        "print(\"Test AUC:\",roc_auc_score(y_test,y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train AUC: 0.7649194737974336\n",
            "Test AUC: 0.7428319644116362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hjmbjxoGf4N"
      },
      "source": [
        "# CONCLUSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sfuveRQGfOd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "1a8571fb-ec6b-424c-b779-2f556f662322"
      },
      "source": [
        "from prettytable import PrettyTable    \n",
        "x = PrettyTable()\n",
        "x.field_names = [\"Architecture\", \"Train AUC\", \"Test AUC\"]\n",
        "x.add_row([\"Model-1\", \"0.84\", \"0.75\"])\n",
        "x.add_row([\"Model-2\", \"0.86\", \"0.71\"])\n",
        "x.add_row([\"Model-3\", \"0.76\", \"0.74\"])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-----------+----------+\n",
            "| Architecture | Train AUC | Test AUC |\n",
            "+--------------+-----------+----------+\n",
            "|   Model-1    |    0.84   |   0.75   |\n",
            "|   Model-2    |    0.86   |   0.71   |\n",
            "|   Model-3    |    0.76   |   0.74   |\n",
            "+--------------+-----------+----------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}